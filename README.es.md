# Esperanza - Asistente Conversacional

Esperanza es un asistente conversacional con personalidad y emociones, capaz de mantener conversaciones contextuales, recordar informaciÃ³n importante y responder en diferentes estilos segÃºn su estado emocional.

## CaracterÃ­sticas

- ğŸ’¬ Interfaz de conversaciÃ³n mediante API REST
- ğŸ§  Memoria persistente para recordar informaciÃ³n importante
- ğŸ˜€ Sistema de emociones que afecta la forma de responder
- ğŸ—£ï¸ IntegraciÃ³n con texto a voz
- ğŸ”„ Soporte para diferentes proveedores de modelos de lenguaje (OpenAI, LM-Studio)
- ğŸ¯ Sistema de objetivos y planificaciÃ³n

## Requisitos

- Node.js 16+
- NPM o Yarn
- Acceso a API de OpenAI (opcional)
- LM-Studio instalado localmente (opcional)

## InstalaciÃ³n

1. Clone el repositorio:

   ```bash
   git clone https://github.com/tuusuario/esperanza.git
   cd esperanza
   ```

2. Instale las dependencias:

   ```bash
   npm install
   ```

3. Configure las variables de entorno:

   ```bash
   cp .env.example .env
   # Edite .env con sus configuraciones
   ```

4. Inicie el servidor:
   ```bash
   npm start
   ```

## ConfiguraciÃ³n

Esperanza puede configurarse a travÃ©s de variables de entorno:

| Variable          | DescripciÃ³n                    | Valores posibles        | Valor por defecto          |
| ----------------- | ------------------------------ | ----------------------- | -------------------------- |
| SERVER_PORT       | Puerto del servidor            | Cualquier puerto vÃ¡lido | 3000                       |
| MODEL_PROVIDER    | Proveedor de modelos LLM       | "openai", "lm-studio"   | "lm-studio"                |
| OPENAI_API_KEY    | Clave API de OpenAI            | String                  | -                          |
| LM_STUDIO_API_URL | URL de la API de LM-Studio     | URL                     | "http://localhost:1234/v1" |
| LLM_STUDIO_MODEL  | Nombre del modelo en LM-Studio | String                  | -                          |

## Arquitectura

El proyecto estÃ¡ estructurado en varios mÃ³dulos:

- **core/server**: ConfiguraciÃ³n del servidor Express y controladores
- **services/agent**: LÃ³gica central del agente conversacional
- **services/memories**: Sistema de memoria persistente
- **services/models**: IntegraciÃ³n con modelos de lenguaje
- **services/voice**: Servicios de texto a voz
- **services/context**: GestiÃ³n de contexto de conversaciÃ³n

## API REST

### Endpoints principales

- `POST /ask`: EnvÃ­a una pregunta al modelo de lenguaje

  ```json
  {
    "question": "Â¿CÃ³mo estÃ¡s hoy?"
  }
  ```

- `POST /say`: Convierte texto a voz

  ```json
  {
    "text": "Hola, Â¿cÃ³mo estÃ¡s?"
  }
  ```

- `GET /sse`: Establece una conexiÃ³n SSE para comunicaciÃ³n en tiempo real

## Desarrollo

### Estructura de directorios

```
src/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ server/       # ConfiguraciÃ³n del servidor
â”œâ”€â”€ services/         # Servicios principales
â”‚   â”œâ”€â”€ agent/        # LÃ³gica del agente
â”‚   â”œâ”€â”€ context/      # GestiÃ³n de contexto
â”‚   â”œâ”€â”€ memories/     # Sistema de memoria
â”‚   â”œâ”€â”€ models/       # IntegraciÃ³n con LLMs
â”‚   â””â”€â”€ voice/        # Servicios de voz
â””â”€â”€ shared/           # Tipos y utilidades compartidas
```

### Tests

Para ejecutar los tests:

```bash
npm test
```

## Contribuir

Las contribuciones son bienvenidas. Por favor, asegÃºrese de aÃ±adir tests para cualquier nueva funcionalidad.

## Licencia

[MIT](LICENSE)
